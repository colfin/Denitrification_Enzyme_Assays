---
title: "Hyde Co. and Pitt Co. Agricultural denitrification structure function"
author: "Colin G. Finlay"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
---
# Setup

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE, warning=FALSE)
#use to set working directory 
knitr::opts_knit$set(root.dir="~/GitHub/Denitrification_Enzyme_Assays/CNH2_comb/analyses")
```

# Load packages and functions

```{r load packages and functions, include FALSE }
#Set source R tools
source("../bin/DiversityFunctions.R")
source("../bin/MothurTools.R")

#load required packages
require("vegan")
require("tidyverse")
require("reshape2")
require("ecodist")
#require("MASS")
#require("MuMIn")
#require("AICcmodavg")
#require("emmeans")
#require("car")
#require("dbstats")
#require("plyr")
require("ggpubr")
#require("labdsv")
require("grid")
#require("multcomp")
#require("multcompView")
require("rstatix")
require("NSM3")
require("ggpmisc")
require("funrar")
require("glue")
```

```{r Bioconductor install and load}
#if (!require("BiocManager", quietly = TRUE))
   # install.packages("BiocManager")
#BiocManager::install(version = "3.22")

require("BiocManager")
```

```{r Phyloseq install and load}
#source("https://raw.githubusercontent.com/joey711/phyloseq/master/inst/scripts/installer.R",
    #   local = TRUE)

#install_phyloseq(branch = "github")

require("phyloseq")

packageVersion('phyloseq')
```

```{r Standard error and confidence intervals}
#Set Std Err and Conf Int
se <- function(x, ...) {
  sd(x, na.rm = TRUE)/sqrt(length(na.omit(x)))
}
ci <- function(x, ...) {
  1.96 * sd(x, na.rm = TRUE)
}
```

# Load files

```{r load files paths}
#Load data files
#Assign file names to variables
sharedfile = "../data/mothur/OTU/Oct25_25/Ag_HC_LD_Oct25Mothur.opti_mcc.shared"
sharedfile2 = "../data/mothur/OTU/Nov2_25/stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.opti_mcc.shared"

taxfile = "../data/mothur/OTU/Oct25_25/Ag_HC_LD_Oct25Mothur.opti_mcc.0.03.cons.taxonomy"
taxfile2 = "../data/mothur/OTU/Nov2_25/stability.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.opti_mcc.0.03.cons.taxonomy"

# denitrification potentials
HC_denit <- read.csv("../../HydeCounty/data/CORRECTED_denit_rates_HydeCo_20221208.csv")
LD_denit <- read.csv("../../PittCounty/data/LD_DenitCalcs_excelMethod.csv")

# soil
N_inorganic <- read.csv("../data/soil/ERL_KCl_data_HC_LD_comb.csv")
pH <- read.csv("../data/soil/HC_LD_Avg_pHs.csv")
C_N_Sal_EC <- read.csv("../data/soil/HC_LD_CN_Sal_EC.csv")
Wet_dry_mass <- read.csv("../data/soil/Wet_mass_dry_mass_HC_LD.csv")
```

```{r read in otu file and trim}
#Read in OTU file
otu2 <- read.otu(sharedfile2)
rownames(otu2)
dim(otu2)

s<- sum(colSums(otu2)) #2250
s

#What sample has lowest read count? 
#otu<- colSums(t(otu.))
otu[which.min(colSums(t(otu2)))]
otu[which.max(colSums(t(otu2)))]

#graph of read counts
d<-as.data.frame(otu2)
d$colsum <- colSums(t(d))
d$group <- rownames(d)
p<-ggplot(d, aes(x=group,y=colsum))+geom_bar(stat="identity")+coord_flip()
p

#Rarefy
#Set min sample number
min.N <- min(rowSums(otu2))
min.N

# new df wich drops the sample with only 2 otu hits:
otu3 <- otu2[rownames(otu2) != "AGLD004bc093", ]

# new min sample number
min.N_2 <- min(rowSums(otu3))
min.N_2

#graph of read counts
d<-as.data.frame(otu3)
d$colsum <- colSums(t(d))
d$group <- rownames(d)
p<-ggplot(d, aes(x=group,y=colsum))+geom_bar(stat="identity")+coord_flip()
p
```

```{r Gemini rarefaction}
# --- Start here with your 'otu2' data frame ---

# 3. Find the minimum sample size (library depth) for rarefaction
# We calculate the total counts for each sample (row)
sample_sums <- rowSums(otu3)

# We find the smallest sample sum to use as our depth
min_depth <- min(sample_sums)

# It's good practice to print this depth
print(paste("Rarefying all samples to a depth of:", min_depth, "reads"))

# 4. Set a random seed for reproducibility
# Rarefaction involves random subsampling. Setting a seed ensures
# that you get the exact same rarefied data every time you run the code.
set.seed(42) 

# 5. Perform rarefaction
# The rrarefy() function takes the community data (otu2) and
# the subsampling depth (min_depth)
otu_rarefied <- rrarefy(otu3, sample = min_depth)

# 6. (OPTIONAL) Check the new row sums to confirm
print("New row sums after rarefaction:")
print(rowSums(otu_rarefied))

# 'otu_rarefied' is your new data frame with rarefied counts
```

Relative abundance using funrar:
- use the package "funrar", and function make_relative() to do relative abundance calculations
  - yields same results as our for loops below
  - has publication: https://doi.org/10.1111/ddi.12629 
- install.packages("funrar")
- require("funrar")
- relative_abundance <- make_relative(as.matrix(Numerical))
```{r relative abundance}
otu_rel <- make_relative(as.matrix(otu_rarefied))
```

```{r read in meta data}
#Read in design file
meta <- read.csv("../data/Design_HC_LD.csv")
```

```{r wrangle meta data}
# remove underscores form meta sampleIDs and make row names
rownames(meta) <- gsub(pattern = "_", replacement = "", x = meta$SampleID)

# remove barcodes from otu_rel row names
# This selects and keeps only the first 7 characters of each row name
rownames(otu_rel) <- substr(rownames(otu_rel), start = 1, stop = 7)

# Get the row names from 'otu_rel' (the data frame with fewer rows)
matching_samples <- rownames(otu_rel)

# 1. Filter and reorder 'meta' to match 'otu_rel'
meta_filtered <- meta[matching_samples, ]

# 2. Now cbind the two data frames, which have identical row names and order
meta_otu <- cbind(meta_filtered, otu_rel)

# (Optional) Check the dimensions to confirm
dim(meta_otu) 
# This should show 49 rows
```

```{r set factors}
meta_otu$Site <- as.factor(meta_otu$Site)
meta_otu$Field_or_Buffer <- as.factor(meta_otu$Field_or_Buffer)
```

# PERMANOVA

```{r PERMANOVA with just end samples}
# PERMANOVA:
metaotu.ad <- adonis2(meta_otu[,-c(1:5)] ~ Site * Field_or_Buffer, method = "bray", data = meta_otu, perm=10000, set.seed=42, by = "terms")
metaotu.ad

# For treatment_salt (Hyde) and maybe Field_Location (if not redundant), analyze within Hyde (and maybe within Pitt)
```

# Indicator species

```{r read and clean taxonomy file}
tax <- import_mothur(mothur_constaxonomy_file =  taxfile)
tax.df <- as.data.frame(tax)

tax.df <- tax.df %>% 
  rownames_to_column(var = "otu")

colnames(tax.df)=c("otu","domain","Phylum","Class", "Order","Family","Genus")

#Clean up taxonomy file. Remove underscores and unclassified
tax.df <- tax.df %>%
    mutate(Family = str_replace(Family, "_family_incertae_sedis", ""), Genus = str_replace(Genus, "_genera_incertae_sedis", "")) %>%
  mutate(Phylum = str_replace_all(Phylum,"_unclassified", ""), Order = str_replace_all(Order,"_unclassified", ""),Class = str_replace_all(Class,"_unclassified", ""), Family = str_replace_all(Family,"_unclassified", ""), Genus = str_replace_all(Genus,"_unclassified", "")) %>%
  mutate(Phylum = str_replace_all(Phylum,"_", " "), Order = str_replace_all(Order,"_", " "),Class = str_replace_all(Class,"_", " "), Family = str_replace_all(Family,"_", " "), Genus = str_replace_all(Genus,"_", " ")) 
```

```{r Indicator Species}
#Final sampling, no field
new.data <-metaotu
new.data$history <- as.factor(new.data$history)
new.data$treatment <- as.factor(new.data$treatment)

#group = interaction(new.data$plant, new.data$treatment, new.data$history) #Setup to analyze all three factors
# Only History and Treatment had significant results in PERMANOVA (i.e., adonis) (see above)
# Therefore, only History and Treatment will be used to group bacterial indicator species analysis:
group.hist <- new.data$history
group.trt <- new.data$treatment

dataREL <- new.data[,-c(1:9)] # Only OTU columns (i.e., relative [REL] abundance data), no metadata columns

dataREL <- dataREL[, colSums(dataREL) > 0.025] # Drop very rare OTUs from the analysis; only analyze most abundant 2.5%

bac.ind_hist <- indval(dataREL, group.hist, numitr = 10000, set.seed(42))
bac.ind_trt <- indval(dataREL, group.trt, numitr = 10000, set.seed(42))

summary(bac.ind_hist)
summary(bac.ind_trt)

# p-value cutoff:
inds_hist <- which(bac.ind_hist$pval <= 0.01)
inds_trt <- which(bac.ind_trt$pval <= 0.01)

# Make data frame skeleton:
bac.indicators_hist <- as.data.frame(matrix(NA, nrow = length(inds_hist), ncol = 4))
bac.indicators_trt <- as.data.frame(matrix(NA, nrow = length(inds_trt), ncol = 4))

# Set column names:
colnames(bac.indicators_hist) <- c("OTU", "Cluster", "IndVal", "Prob")
colnames(bac.indicators_trt) <- c("OTU", "Cluster", "IndVal", "Prob")

# Poplulate OTU column:
bac.indicators_hist$OTU <- names(inds_hist)
bac.indicators_trt$OTU <- names(inds_trt)

# Populate Cluster column:
bac.indicators_hist$Cluster <- bac.ind_hist$maxcls[inds_hist]
bac.indicators_trt$Cluster <- bac.ind_trt$maxcls[inds_trt]

# Populate IndVal column:
bac.indicators_hist$IndVal <- bac.ind_hist$indcls[inds_hist]
bac.indicators_trt$IndVal <- bac.ind_trt$indcls[inds_trt]

# Populate p-value column:
bac.indicators_hist$Prob <- bac.ind_hist$pval[inds_hist]
bac.indicators_trt$Prob <- bac.ind_trt$pval[inds_trt]

otu.tax <- as.data.frame(tax.df)

ind.tax_hist <- otu.tax[which(as.character(otu.tax$otu) %in% bac.indicators_hist$OTU), ]
ind.tax_trt <- otu.tax[which(as.character(otu.tax$otu) %in% bac.indicators_trt$OTU), ]

ind.tax_hist <- ind.tax_hist[match(ind.tax_hist$otu, bac.indicators_hist$OTU), ]
ind.tax_trt <- ind.tax_trt[match(ind.tax_trt$otu, bac.indicators_trt$OTU), ]

# Add taxonomic information:
indicator.bac_hist <- cbind(bac.indicators_hist, ind.tax_hist[, -c(1)])
indicator.bac_trt <- cbind(bac.indicators_trt, ind.tax_trt[, -c(1)])

# Order rows by Cluster:
indicator.bac_hist <- indicator.bac_hist[order(as.numeric(indicator.bac_hist$Cluster)), ]
indicator.bac_trt <- indicator.bac_trt[order(as.numeric(indicator.bac_trt$Cluster)), ]

# Print information from tables:
table(indicator.bac_hist$Cluster)
table(indicator.bac_trt$Cluster)

table(indicator.bac_hist$Phylum)
table(indicator.bac_trt$Phylum)

# Identify what the Cluster numbers mean:
levels(group.hist)
levels(group.trt)

#Replace cluster numbers with factor names:
indicator.bac_hist["Cluster"][indicator.bac_hist["Cluster"] == 1] <- "Dry"
indicator.bac_trt["Cluster"][indicator.bac_trt["Cluster"] == 1] <- "Dry"

indicator.bac_hist["Cluster"][indicator.bac_hist["Cluster"] == 2] <- "Interim"
indicator.bac_trt["Cluster"][indicator.bac_trt["Cluster"] == 2] <- "Interim"

indicator.bac_hist["Cluster"][indicator.bac_hist["Cluster"] == 3] <- "Wet"
indicator.bac_trt["Cluster"][indicator.bac_trt["Cluster"] == 3] <- "Wet"

#Find overlapping indicator tax in hist and trt:
common_indicators <- generics::intersect(indicator.bac_hist$OTU, indicator.bac_trt$OTU)
common_indicators <- as.data.frame(common_indicators) #Make it a data frame
colnames(common_indicators) <- "OTU" #Rename column header to "OTU" to match with indicator.bac_hist and indicator.bac_trt

common_indicators <- left_join(common_indicators, indicator.bac_hist, by = "OTU") #Add data from indicator.bac_hist
colnames(common_indicators)[2:4] <- c("Cluster_hist", "IndVal_hist", "Prob_hist") #Rename to not confuse with treatment indicators, added next:
  #Add data from indicator.bac_trt:
common_indicators <- left_join(common_indicators, indicator.bac_trt, by = c("OTU", "domain", "Phylum", "Class", "Order", "Family", "Genus")) 
colnames(common_indicators)[11:13] <- c("Cluster_treatment", "IndVal_treatment", "Prob_treatment")

# Export Bacteria Indicator Tables:
#write.table(indicator.bac_hist, "../figures/pub/BacterialIndicators_History.txt",
           #sep="\t", row.names = F, quote = F)

#write.table(indicator.bac_trt, "../figures/pub/BacterialIndicators_Treatment.txt",
            #sep="\t", row.names = F, quote = F)
```

# Denitrification and soil parameters

```{r denit wrangling}
# remove NO_ACET
HC_denit_acet <- HC_denit %>%
  dplyr::filter(Acetylene == "ACET", .preserve = TRUE)

LD_denit_acet <- LD_denit %>%
  dplyr::filter(Acetylene == "ACET", .preserve = TRUE)

# for HC, remove extra samples 1 through 4
# Create a vector of the SampleIDs to exclude
values_to_remove <- c("AG_HC_001_ACET", "AG_HC_002_ACET", "AG_HC_003_ACET", "AG_HC_004_ACET")

HC_denit_acet_filtered <- HC_denit_acet[!(HC_denit_acet$Sample_ID %in% values_to_remove), ]

# rbind HC and LD
# first, need to simplify so column number and names match
HC_denit_simple <- HC_denit_acet_filtered[,c(1,6)]
LD_denit_simple <- LD_denit_acet[, c(1,8)]

comb_denit_simple <- rbind(HC_denit_simple, LD_denit_simple)

# row names to match PCoA
# get rid of underscores
rownames(comb_denit_simple) <- gsub(pattern = "_", replacement = "", x = comb_denit_simple$Sample_ID)

# This selects and keeps only the first 7 characters of each row name
rownames(comb_denit_simple) <- substr(rownames(comb_denit_simple), start = 1, stop = 7)
```

```{r soil wrangling}
#Wet_dry_mass
# add dry_proportion (dry/wet)
Wet_dry_mass$dry_proportion <- Wet_dry_mass$dry_soil_g / Wet_dry_mass$wet_soil_g

# add percent soil moisture
Wet_dry_mass$PercentMoisture <- ((Wet_dry_mass$wet_soil_g - Wet_dry_mass$dry_soil_g) / Wet_dry_mass$wet_soil_g) * 100

#N_inorganic
# add dry_proportion column
N_inorganic$dry_proportion <- Wet_dry_mass$dry_proportion

# Calculate dry soil input for KCl extraction (dry soil input = wet g * dry_proportion)
N_inorganic$dry_soil_g <- N_inorganic$KCl_field_moist_g_soil * N_inorganic$dry_proportion

# divide mg/L by dry g for final unit to use in simplified data frame


#pH
#C_N_Sal_EC



```



# PCoA

```{r wrangling}
soil.finish_FULL <- soil %>% 
dplyr::select(-c(g.soil.kcl, no2.no3.mg.l, plant.c.percent, plant.n.percent, plant.dry.mass.g, HM., CEC.))

# soil finish, only finish samples:
soil.finish_FULL <- soil.finish_FULL %>%
  filter(time == "finish")

# make chamber row names
rownames(soil.finish_FULL) <- soil.finish_FULL$chamber

# remove design info and NOx column that has many NAs
meta.env_FULL <- soil.finish_FULL[, -c(1:5)]

# Add GHG fluxes from final time point, August 11
meta.env_GHG <- cbind(meta.env_FULL, select_fluxes_combined_w_T0_8.11$f0_CH4, select_fluxes_combined_w_T0_8.11$f0_CO2, select_fluxes_combined_w_T0_8.11$f0_N2O)

colnames(meta.env_GHG)[19:21] <- c("f0_CH4", "f0_CO2", "f0_N2O")


# Now ready for new PCoA calculation without interim, then envfit to meta.env_GHG
```

```{r Calculate distance matrix and PCoA components without field, end samples only}
# Bray-Curtis distance matrix:
otu.rel.dist<-vegdist(otu_rel, method="bray")

# Principal Coordinates Analysis
otu.rel.dist.pcoa <- cmdscale(otu.rel.dist, k=2, eig=TRUE, add=TRUE)
# Classical (Metric) Multidimensional Scaling; returns PCoA coordinates
# eig=TRUE returns eigenvalues; k = # of dimensions to calculate

explainvar1a <- round(otu.rel.dist.pcoa$eig[1] / sum(otu.rel.dist.pcoa$eig), 3) * 100
explainvar2a <- round(otu.rel.dist.pcoa$eig[2] / sum(otu.rel.dist.pcoa$eig), 3) * 100
sum.eiga <- sum(explainvar1a, explainvar2a)

explainvar1a # 15.8%
explainvar2a # 6%
sum.eiga # 21.8%
```

```{r plot PCoA without field, end samples only}
pcoa.groups <- paste(meta_otu$Site, meta_otu$Field_or_Buffer, sep = "_")
pcoa.points <- data.frame(otu.rel.dist.pcoa$points, group = pcoa.groups)

# Calculate Centroids (mean and SE)
pcoa.L.centroids <- reshape2::melt(pcoa.points, id="group", measure.vars = c("X1", "X2"))
pcoa.centroids <- acast(pcoa.L.centroids, variable ~ group, mean)
pcoa.centroids.se <- acast(pcoa.L.centroids, variable ~ group, se)
pcoa.centroids.sd <- acast(pcoa.L.centroids, variable ~ group, sd)

# Combine
pcoa.cent.dataframe <- cbind(t(pcoa.centroids), t(pcoa.centroids.se))
colnames(pcoa.cent.dataframe) <- c("V1", "V2", "V1e", "V2e")

# Adding columns with the factors. H: hydrologic history
pcoa_Site <- c("HydeCo", "HydeCo", "PittCo", "PittCo")
pcoa_field_or_buff <- c("buffer", "field", "buffer", "field")

# create and add to "trts" data frame
pcoa.cent.dataframe.trts <- as.data.frame(pcoa.cent.dataframe) 
pcoa.cent.dataframe.trts$Site <- as.factor(pcoa_Site)
pcoa.cent.dataframe.trts$Field_or_Buffer <- as.factor(pcoa_field_or_buff)
pcoa.cent.dataframe.trts$centroid_or_sample <- "centroid"

# Add in points to data frame:
pcoa.points_ForPlot <- pcoa.points
colnames(pcoa.points_ForPlot) <- c("V1", "V2", "group")

# Add labels to match ...cent.dataframe.trts
pcoa.points_ForPlot$Site <- meta_otu$Site
pcoa.points_ForPlot$Field_or_Buffer <- meta_otu$Field_or_Buffer

#remove "group" column
pcoa.points_ForPlot <- pcoa.points_ForPlot[, -3]
#add V1e and V2e as zeros:
pcoa.points_ForPlot$V1e <- numeric(49)
pcoa.points_ForPlot$V2e <- numeric(49)
# Add column to distinguish sample points from centroids, and later use to set alpha in plot
pcoa.points_ForPlot$centroid_or_sample <- "sample"

#Merge:
centroids_points_merged <- rbind(pcoa.cent.dataframe.trts, pcoa.points_ForPlot)

# Add combined site and field or buffer column:
centroids_points_merged$Site_field_buff <- paste(centroids_points_merged$Site, centroids_points_merged$Field_or_Buffer, sep = "_")

centroids_points_merged$Site_field_buff <- as.factor(centroids_points_merged$Site_field_buff)
```

```{r Wrangle envfit data frame}

```


```{r}
# pcoa points data frame for envfit
pcoa_DF <- as.data.frame(otu.rel.dist.pcoa$points)

#Run envfit with new Soil data (SSF = Soil Start & Finish):
fit_denit_SSF <- envfit(pcoa_DF, SoilGHG_StartFinish_Envfit, permutations = 10000, set.seed(42))
fit_denit_SSF

A_denit_SSF <-as.list(fit_denit_SSF$vectors)
vec_denit_SSF <- as.data.frame(fit_denit_SSF$vectors$arrows*sqrt(fit_denit_SSF$vectors$r)*0.15)
p_denit_SSF <- as.data.frame(A_denit_SSF$pvals)
vec_denit_SSF <- cbind(vec_denit_SSF, p_denit_SSF)
vec_denit_SSF <- subset(vec_denit_SSF, A_denit_SSF$pvals<=0.1) # alpha = 0.1 for EcoSphere paper


#Plot using ggplot2
df <- as.data.frame(centroids_points_merged)

plot_pcoa <- ggplot(df, aes(x=V1, y=V2, shape=Site_field_buff)) + geom_errorbarh(aes(xmax=V1+V1e, xmin=V1-V1e, height=0.003), colour="black") +    
  geom_errorbar(aes(ymax=V2+V2e, ymin=V2-V2e, width=0.003), colour="black") +   
  geom_point(aes(shape = Site_field_buff, alpha = centroid_or_sample, size = centroid_or_sample), stroke=2) +  
  theme_bw() +
  scale_size_manual(values = c(6, 3), name = "Centroid or Sample")+
  scale_alpha_manual(values = c(1, 0.3), name = "Centroid or Sample")+
  #scale_color_manual(values=c("black", "#997700", "#004488"), name="Treatment") +
  scale_shape_manual(values = c(0, 15, 1, 19), name="Site_Buffer") +
  xlab(glue("PCoA 1 ({explainvar1a}%)")) + ylab(glue("PCoA 2 ({explainvar2a}%)")) + 
  #geom_segment(data=vec_denit_SSF, aes(x=0,xend=V1,y=0,yend=V2), linewidth=1, arrow = arrow(length = unit(0.2, "cm")),colour="black", alpha = 0.4, inherit.aes=F)+ 
 #geom_text(data=vec_denit_SSF, aes(x=V1-0.005, y=V2-0.005), label= expression(paste("CO"[2])), size=4, inherit.aes=F)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + 
  theme(panel.background = element_blank()) + 
  theme(axis.title = element_text(size=14), axis.text=element_text(size=14), 
          axis.text.x = element_text(size=14),  axis.text.y = element_text(size=14),
          panel.border = element_rect(colour = "black", linewidth=1.25)) +
  theme(axis.ticks.length=unit(0.3,"cm")) + 
  theme(plot.title=element_text(size=14)) +
  theme(legend.text=element_text(size=14), legend.title = element_text(size=14))+
  guides(shape = guide_legend(override.aes = list(size = 4), order = 1), 
           colour = guide_legend(override.aes = list(pch=16, size = 4), order = 2)) +
    ggtitle("")

plot_pcoa

#ggsave("~/Desktop/newDenitPCoa.jpeg", plot = plot2a, device="jpeg", path=NULL, scale=1, height = 7, width = 10, limitsize = TRUE, dpi = 300)
```



# Distance-based partial least squares regression (dbplsr)

```{r Euclidean distance matrices}
# Calculate euclidean distances for soil parameters only, soil parameters and GHGs, and GHGs only:
soilonly.dist <- vegdist(x = scale(meta.env_GHG[, -c(19:21)]), "euclid")
soilghg.dist <- vegdist(x = scale(meta.env_GHG), "euclid")
ghg.dist <- vegdist(x = scale(meta.env_GHG[, c(19:21)]), "euclid")
```

```{r DBPLSR}
#distance-based partial least squares regression (DBPLSR)
#Compares distance matrices. can use mixture of continuous and qualitative variables. 
#Method good when factors are may and highly co-linear. A PLS model find the multidimensional direction in the Z space that explains the variance in the Y space. 

# GHGs compared to Bray-Curtis Distance matrix of rarified OTUs: 
dbplsr.ch4 <- dbplsr(f0_CH4 ~ as.matrix(otu.2.rel.dist), data=meta.env_GHG , ncomp=30, method="GCV")
summary(dbplsr.ch4)

dbplsr.co2 <- dbplsr(f0_CO2 ~ as.matrix(otu.2.rel.dist), data=meta.env_GHG , ncomp=30, method="GCV")
summary(dbplsr.co2)

dbplsr.n2o <- dbplsr(f0_N2O ~ as.matrix(otu.2.rel.dist), data=meta.env_GHG , ncomp=31, method="GCV")
summary(dbplsr.n2o)

# GHGs compared to euclidean distance matrix of soil parameters (sp): 
dbplsr.sp.ch4 <- dbplsr(f0_CH4 ~ as.matrix(soilonly.dist), data=meta.env_GHG , ncomp=35, method="GCV")
summary(dbplsr.sp.ch4)

dbplsr.sp.co2 <- dbplsr(f0_CO2 ~ as.matrix(soilonly.dist), data=meta.env_GHG , ncomp=35, method="GCV")
summary(dbplsr.sp.co2)

dbplsr.sp.n2o <- dbplsr(f0_N2O ~ as.matrix(soilonly.dist), data=meta.env_GHG , ncomp=35, method="GCV")
summary(dbplsr.sp.n2o)
```

# Mantel test: soil and bacterial community

```{r mantel soil and bac comm }
# For reproducibility, confirm that random seed is set:
set.seed(42)

#soil only
bac.soil.mantel.1 <- vegan::mantel(as.matrix(soilonly.dist), as.matrix(otu.2.rel.dist), method="pearson", permutations=10000)
bac.soil.mantel.1

#soil and ghg
bac.soil.mantel.2 <- vegan::mantel(as.matrix(soilghg.dist), as.matrix(otu.2.rel.dist), method="pearson", permutations=10000)
bac.soil.mantel.2

#ghg only 
bac.soil.mantel.3 <- vegan::mantel(as.matrix(ghg.dist), as.matrix(otu.2.rel.dist), method="pearson", permutations=10000)
bac.soil.mantel.3
```

# Greenhouse gas and redox regressions

```{r wrangling}
# Create IRIS start and finish data frame:
IRIS_start_Fin <- soil %>%
  filter(time != "field") %>%
  dplyr::select(c("chamber", "time", "history", "treatment", "plant", "redox.percent.paint.removed"))

# Create GHG start and finish data frame from select_fluxes_combined:
GHG_flux_start_fin <- select_fluxes_combined_w_T0 %>%
  dplyr::filter(date_format == "13-Jun" | date_format == "11-Aug") %>%
  dplyr::select(c("f0_CH4", "f0_CO2", "f0_N2O", "plant", "treatment", "history", "chamber", "date_format"))

# Set levels of time so facets are ordered correctly
IRIS_start_Fin$time <- factor(IRIS_start_Fin$time, levels = c("start", "finish"))

# Adjust labels
IRIS_start_Fin$time <- revalue(IRIS_start_Fin$time, c(start = "Start (Week 0)", finish = "Finish (Week 8)"))

# reorder df
IRIS_start_Fin <- IRIS_start_Fin %>%
  arrange(time)

# Combine the IRIS and GHG dfs:
IRIS_GHG_start_fin <- cbind(IRIS_start_Fin, GHG_flux_start_fin)

# Remove extra columns:
IRIS_GHG_start_fin <- IRIS_GHG_start_fin[,-c(10:13)]

# Change history, treatment, and plant to factors:
IRIS_GHG_start_fin$history <- as.factor(IRIS_GHG_start_fin$history)
IRIS_GHG_start_fin$treatment <- as.factor(IRIS_GHG_start_fin$treatment)
IRIS_GHG_start_fin$plant <- as.factor(IRIS_GHG_start_fin$plant)

# Format redox.percent.paint.removed as percent:
IRIS_GHG_start_fin$redox.percent.formatted <- IRIS_GHG_start_fin$redox.percent.paint.removed * 100
```


```{r CH4 redox regression}
# Check linear models:
ch4.lm.start <- lm(f0_CH4 ~ redox.percent.formatted, data=IRIS_GHG_start_fin, subset = date_format == "13-Jun")
summary(ch4.lm.start)

ch4.lm.finish <- lm(f0_CH4 ~ redox.percent.formatted, data=IRIS_GHG_start_fin, subset = date_format == "11-Aug")
summary(ch4.lm.finish)

# To use open and closed shapes, must create a combined category for History and Plant:
IRIS_GHG_start_fin$history_plant <- as.factor(c(paste(IRIS_GHG_start_fin$history, IRIS_GHG_start_fin$plant, sep = "_")))

# Filter data for geom_smooth only where p < 0.1
ch4_smooth_data <- IRIS_GHG_start_fin %>% filter(time == "Start (Week 0)")

# Plot
ch4.redox.regress.plot <- ggplot(IRIS_GHG_start_fin, x=redox.percent.formatted, y=f0_CH4)  +
  facet_wrap(~time, nrow = 1, ncol = 2)+
                    geom_point(aes(x=redox.percent.formatted, y=f0_CH4, color=treatment, shape=history_plant), size = 2) +
  scale_color_manual(values=c("#997700","#6699CC","#004488"), labels = c("Dry", "Interim", "Wet"), name="Treatment")+
  scale_shape_manual(labels = c("Dry_No Plant", "Dry_Plant", "Interim_No Plant", "Interim_Plant", "Wet_No Plant", "Wet_Plant"), values = c(0, 15, 2, 17, 1, 19), name="History_Plant")+
  geom_smooth(data = ch4_smooth_data, aes(x=redox.percent.formatted, y=f0_CH4), formula = y ~ x, method=lm, se=T, color="black")+
  stat_poly_eq(aes(x=redox.percent.formatted, y=f0_CH4, label = paste(after_stat(adj.rr.label), after_stat(p.value.label), sep = "*\", \"*")), data = IRIS_GHG_start_fin, formula = y ~ x, method = "lm", label.y = "top",label.x = "right")+
  theme_bw()  +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
          axis.title.y=element_text(margin=margin(r=10)), 
          axis.title.x=element_text(margin=margin(t=10))) +
    theme(axis.title=element_text(vjust=1,size=20),
          axis.text=element_text(size=20), axis.text.x = element_text(size=20), panel.border =
          element_rect(colour = "black",size=1)) + 
    theme(axis.ticks.length=unit(0.3,"cm")) + labs(x = "", y = expression(paste("mg CH"[4]," m"^{-2}, " h"^{-1}))) + 
    theme(legend.text=element_text(size=20), legend.title = element_text(size=20), 
          legend.position = "right")+
    theme(strip.text = element_text(size = 20))

ch4.redox.regress.plot
```

```{r CO2 redox regression}
co2.lm.start <- lm(f0_CO2 ~ redox.percent.formatted, data=IRIS_GHG_start_fin, subset = date_format == "13-Jun")
summary(co2.lm.start)

co2.lm.finish <- lm(f0_CO2 ~ redox.percent.formatted, data=IRIS_GHG_start_fin, subset = date_format == "11-Aug")
summary(co2.lm.finish)

# Filter data for geom_smooth only where p < 0.1
co2_smooth_data <- IRIS_GHG_start_fin %>% filter(time == "Finish (Week 8)")

# Plot
co2.redox.regress.plot <- ggplot(IRIS_GHG_start_fin, x=redox.percent.formatted, y=f0_CO2)  +
  facet_wrap(~time, nrow = 1, ncol = 2)+
                    geom_point(aes(x=redox.percent.formatted, y=f0_CO2, color=treatment, shape=history_plant), size = 2) +
  scale_color_manual(values=c("#997700","#6699CC","#004488"), labels = c("Dry", "Interim", "Wet"), name="Treatment")+
  scale_shape_manual(labels = c("Dry_No Plant", "Dry_Plant", "Interim_No Plant", "Interim_Plant", "Wet_No Plant", "Wet_Plant"), values = c(0, 15, 2, 17, 1, 19), name="History_Plant")+
  geom_smooth(data = co2_smooth_data, aes(x=redox.percent.formatted, y=f0_CO2), formula = y ~ x, method=lm, se=T, color="black")+
  stat_poly_eq(aes(x=redox.percent.formatted, y=f0_CO2, label = paste(after_stat(adj.rr.label), after_stat(p.value.label), sep = "*\", \"*")), data = IRIS_GHG_start_fin, formula = y ~ x, method = "lm", label.y = "top",label.x = "right")+
  theme_bw()  +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
          axis.title.y=element_text(margin=margin(r=10)), 
          axis.title.x=element_text(margin=margin(t=10))) +
    theme(axis.title=element_text(vjust=1,size=20),
          axis.text=element_text(size=20), axis.text.x = element_text(size=20), panel.border =
          element_rect(colour = "black",size=1)) + 
    theme(axis.ticks.length=unit(0.3,"cm")) + labs(x = "", y = expression(paste("mg CO"[2]," m"^{-2}, " h"^{-1}))) + 
    theme(legend.text=element_text(size=20), legend.title = element_text(size=20), 
          legend.position = "right")+
    theme(strip.text = element_text(size = 20))

co2.redox.regress.plot
```

```{r N2O redox regression }
n2o.lm.start <- lm(f0_N2O ~ redox.percent.formatted, data=IRIS_GHG_start_fin, subset = date_format == "13-Jun")
summary(n2o.lm.start)

n2o.lm.finish <- lm(f0_N2O ~ redox.percent.formatted, data=IRIS_GHG_start_fin, subset = date_format == "11-Aug")
summary(n2o.lm.finish)

n2o.redox.regress.plot <- ggplot(IRIS_GHG_start_fin, x=redox.percent.formatted, y=f0_N2O)  +
  facet_wrap(~time, nrow = 1, ncol = 2)+
                    geom_point(aes(x=redox.percent.formatted, y=f0_N2O, color=treatment, shape=history_plant), size = 2) +
  scale_color_manual(values=c("#997700","#6699CC","#004488"), labels = c("Dry", "Interim", "Wet"), name="Treatment")+
  scale_shape_manual(labels = c("Dry_No Plant", "Dry_Plant", "Interim_No Plant", "Interim_Plant", "Wet_No Plant", "Wet_Plant"), values = c(0, 15, 2, 17, 1, 19), name="History_Plant")+
  #geom_smooth(aes(x=redox.percent.formatted, y=f0_N2O), formula = y ~ x, method=lm, se=T, color="black")+
  stat_poly_eq(aes(x=redox.percent.formatted, y=f0_N2O, label = paste(after_stat(adj.rr.label), after_stat(p.value.label), sep = "*\", \"*")), data = IRIS_GHG_start_fin, formula = y ~ x, method = "lm", label.y = "bottom",label.x = "right")+
  theme_bw()  +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
          axis.title.y=element_text(margin=margin(r=10)), 
          axis.title.x=element_text(margin=margin(t=10))) +
    theme(axis.title=element_text(vjust=1,size=20),
          axis.text=element_text(size=20), axis.text.x = element_text(size=20), panel.border =
          element_rect(colour = "black",size=1)) + 
    theme(axis.ticks.length=unit(0.3,"cm")) + labs(x = "IRIS Percent Paint Removed", y = expression(paste("mg N"[2],"O m"^{-2}, " h"^{-1}))) + 
    theme(legend.text=element_text(size=20), legend.title = element_text(size=20), 
          legend.position = "right")+
    theme(strip.text = element_text(size = 20))

n2o.redox.regress.plot
```

```{r Panel together GHG ~ redox regressions}
GHG_redox_3panel <- ggarrange(ch4.redox.regress.plot, co2.redox.regress.plot, n2o.redox.regress.plot, labels = c("(a)", "(b)", "(c)"), ncol = 1, nrow = 3, legend = "right", common.legend = T, align = "hv")

GHG_redox_3panel

#ggsave("../figures/Ecosphere_pub/redox_regres.tiff", plot=GHG_redox_3panel, device="tiff", path=NULL, scale=1, width=14, height=12, dpi=600, limitsize=TRUE, bg="white")

#ggsave("../figures/Ecosphere_pub/redox_regres.png", plot=GHG_redox_3panel, device="png", path=NULL, scale=1, width=14, height=12, dpi=600, limitsize=TRUE, bg="white")
```

